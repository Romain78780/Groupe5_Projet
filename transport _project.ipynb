{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5118fe1-efcc-42e7-a1ab-52a01fda9020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\smoha\\miniconda3\\envs\\transports_project\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\smoha\\miniconda3\\envs\\transports_project\\lib\\site-packages (2.0.34)\n",
      "Requirement already satisfied: psycopg2 in c:\\users\\smoha\\miniconda3\\envs\\transports_project\\lib\\site-packages (2.9.9)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\smoha\\miniconda3\\envs\\transports_project\\lib\\site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\smoha\\miniconda3\\envs\\transports_project\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\smoha\\miniconda3\\envs\\transports_project\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\smoha\\miniconda3\\envs\\transports_project\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\smoha\\miniconda3\\envs\\transports_project\\lib\\site-packages (from sqlalchemy) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\smoha\\miniconda3\\envs\\transports_project\\lib\\site-packages (from sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\smoha\\miniconda3\\envs\\transports_project\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas sqlalchemy psycopg2 openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b1d8fd3-1d3e-479b-9d56-0d701d57d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "import psycopg2\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e5688bc-fe07-423b-9032-0e8baf38a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_lake_path = Path(\"C:/Users/smoha/DataLake_Groupe5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c1a83a1-53e7-46e5-814e-590104345df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = pd.read_csv(\"C:/Users/smoha/DataLake_Groupe5/transport_data/reference_data/stops/transit_stops.csv\",sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb6955f4-c1e3-4ca7-ae02-661687cf54fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   stop_id  stop_code         stop_name  stop_desc   stop_lat  stop_lon  \\\n",
      "0       57        NaN          8 MAI 45        NaN  49.099805  6.138669   \n",
      "1       46        NaN          8 MAI 45        NaN  49.099927  6.138371   \n",
      "2      450        NaN  11ème D'AVIATION        NaN  49.085890  6.146239   \n",
      "3      852        NaN  11ème D'AVIATION        NaN  49.086159  6.145297   \n",
      "4      323        NaN           18 AOUT        NaN  49.191534  6.034971   \n",
      "\n",
      "   zone_id                                     stop_url  location_type  \\\n",
      "0      NaN  https://services.lemet.fr/fr/biv/arret/1530              0   \n",
      "1      NaN  https://services.lemet.fr/fr/biv/arret/1530              0   \n",
      "2      NaN  https://services.lemet.fr/fr/biv/arret/7264              0   \n",
      "3      NaN  https://services.lemet.fr/fr/biv/arret/7264              0   \n",
      "4      NaN                                          NaN              0   \n",
      "\n",
      "   parent_station  wheelchair_boarding  \n",
      "0             NaN                    2  \n",
      "1             NaN                    2  \n",
      "2             NaN                    2  \n",
      "3             NaN                    2  \n",
      "4             NaN                    1  \n"
     ]
    }
   ],
   "source": [
    "print(stops.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b97bf8e-9f87-44a5-be45-c36a62db5fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les colonnes dans la même commande et réaffecter à stops\n",
    "stops = stops.drop(columns=[\n",
    " \"stop_code\",\n",
    "    \"stop_desc\",\n",
    "    \"zone_id\",\n",
    "    \"stop_url\",\n",
    "    \"location_type\",\n",
    "    \"parent_station\",\n",
    "    \"wheelchair_boarding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4b90cf2-1040-4e96-b3c1-0164e28ef932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes restantes : ['stop_id', 'stop_name', 'stop_lat', 'stop_lon']\n"
     ]
    }
   ],
   "source": [
    "print(\"Colonnes restantes :\", stops.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce2632b2-4ba6-4031-8b1e-7601e6a909e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   stop_id         stop_name   stop_lat  stop_lon\n",
      "0       57          8 MAI 45  49.099805  6.138669\n",
      "1       46          8 MAI 45  49.099927  6.138371\n",
      "2      450  11ème D'AVIATION  49.085890  6.146239\n",
      "3      852  11ème D'AVIATION  49.086159  6.145297\n",
      "4      323           18 AOUT  49.191534  6.034971\n"
     ]
    }
   ],
   "source": [
    "print(stops.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0048c9ba-43e6-4be9-8c4d-953bd22614c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stops.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7df61108-f5bb-4f27-95e6-34bd6db45b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   stop_id         stop_name   stop_lat  stop_lon\n",
      "0       57          8 MAI 45  49.099805  6.138669\n",
      "1       46          8 MAI 45  49.099927  6.138371\n",
      "2      450  11ème D'AVIATION  49.085890  6.146239\n",
      "3      852  11ème D'AVIATION  49.086159  6.145297\n",
      "4      323           18 AOUT  49.191534  6.034971\n"
     ]
    }
   ],
   "source": [
    "print(stops.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9a50eaa-cba1-4ce0-810a-e006705c03ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doublons pour la colonne 'stop_id':\n",
      "Empty DataFrame\n",
      "Columns: [stop_id]\n",
      "Index: []\n",
      "----------------------------------------\n",
      "Doublons pour la colonne 'stop_name':\n",
      "             stop_name\n",
      "0             8 MAI 45\n",
      "1             8 MAI 45\n",
      "2     11ème D'AVIATION\n",
      "3     11ème D'AVIATION\n",
      "4              18 AOUT\n",
      "...                ...\n",
      "1040       ZAC D'AUGNY\n",
      "1042        ZAC PELTRE\n",
      "1043        ZAC PELTRE\n",
      "1044      ZONE HERGOTT\n",
      "1045      ZONE HERGOTT\n",
      "\n",
      "[959 rows x 1 columns]\n",
      "----------------------------------------\n",
      "Doublons pour la colonne 'stop_lat':\n",
      "       stop_lat\n",
      "32    49.121440\n",
      "41    49.101866\n",
      "42    49.101866\n",
      "54    49.075620\n",
      "63    49.096509\n",
      "...         ...\n",
      "1023  49.151940\n",
      "1035  49.150349\n",
      "1036  49.150349\n",
      "1037  49.151276\n",
      "1038  49.151276\n",
      "\n",
      "[80 rows x 1 columns]\n",
      "----------------------------------------\n",
      "Doublons pour la colonne 'stop_lon':\n",
      "      stop_lon\n",
      "41    6.224284\n",
      "42    6.224284\n",
      "45    6.224181\n",
      "46    6.224181\n",
      "90    6.168920\n",
      "...        ...\n",
      "998   6.058151\n",
      "999   6.058151\n",
      "1008  6.094864\n",
      "1009  6.094864\n",
      "1025  6.172134\n",
      "\n",
      "[65 rows x 1 columns]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for column in stops.columns:\n",
    "    print(f\"Doublons pour la colonne '{column}':\")\n",
    "    # Filtrer les lignes où la colonne a des doublons\n",
    "    duplicates = stops[stops.duplicated(subset=[column], keep=False)]\n",
    "    print(duplicates[[column]])  # Afficher les doublons pour la colonne\n",
    "    print('-' * 40)  # Ligne de séparation pour lisibilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fe623be-5141-4395-8174-d03967145ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes vides : 0\n"
     ]
    }
   ],
   "source": [
    "empty_rows_count = stops.isna().all(axis=1).sum()\n",
    "\n",
    "# Afficher le nombre de lignes vides\n",
    "print(f\"Nombre de lignes vides : {empty_rows_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "456c3401-4cd6-414d-9b18-cff94bff7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = pd.read_csv(\"C:/Users/smoha/DataLake_Groupe5/transport_data/reference_data/shapes/route_shapes.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a287388a-2b15-4177-844c-1ee5330cf315",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = shapes.drop(columns=[\"shape_pt_sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60d507fa-493e-46da-b0d7-c556927dae1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   shape_id  shape_pt_lat  shape_pt_lon\n",
      "0   10008.0     49.125193      6.230550\n",
      "1   10008.0     49.125861      6.227397\n",
      "2   10008.0     49.125861      6.227397\n",
      "3   10008.0     49.123956      6.225906\n",
      "4   10008.0     49.123956      6.225906\n"
     ]
    }
   ],
   "source": [
    "print(shapes.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59f4ab82-e7aa-490b-b5f4-42ae81547b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_lat    0\n",
      "stop_lon    0\n",
      "dtype: int64\n",
      "   stop_id         stop_name   stop_lat  stop_lon\n",
      "0       57          8 MAI 45  49.099805  6.138669\n",
      "1       46          8 MAI 45  49.099927  6.138371\n",
      "2      450  11ème D'AVIATION  49.085890  6.146239\n",
      "3      852  11ème D'AVIATION  49.086159  6.145297\n",
      "4      323           18 AOUT  49.191534  6.034971\n"
     ]
    }
   ],
   "source": [
    "# Vérifier les valeurs manquantes dans les colonnes \"stop_lat\" et \"stop_lon\"\n",
    "print(stops[['stop_lat', 'stop_lon']].isnull().sum())\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes dans les colonnes \"stop_lat\" et \"stop_lon\"\n",
    "stops_clean = stops.dropna(subset=['stop_lat', 'stop_lon'])\n",
    "\n",
    "# Vérifier si le problème persiste après suppression des lignes manquantes\n",
    "print(stops_clean.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd5a7e2e-0511-4282-9792-3172962bd7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_id        int64\n",
      "stop_name     object\n",
      "stop_lat     float64\n",
      "stop_lon     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convertir les colonnes de latitude et longitude en float\n",
    "stops['stop_lat'] = pd.to_numeric(stops['stop_lat'], errors='coerce')\n",
    "stops['stop_lon'] = pd.to_numeric(stops['stop_lon'], errors='coerce')\n",
    "\n",
    "# Vérifier le type des colonnes après conversion\n",
    "print(stops.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce74183d-89ab-4a06-90b7-4652959d429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_lat    0\n",
      "stop_lon    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(stops[['stop_lat', 'stop_lon']].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31c405cd-8bbe-446c-b3b4-67f761625e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_lat    0\n",
      "stop_lon    0\n",
      "dtype: int64\n",
      "          stop_lat     stop_lon\n",
      "count  1046.000000  1046.000000\n",
      "mean     49.110793     6.169397\n",
      "std       0.030441     0.052667\n",
      "min      48.998825     6.003117\n",
      "25%      49.093802     6.145880\n",
      "50%      49.111007     6.170715\n",
      "75%      49.128127     6.203619\n",
      "max      49.204139     6.324477\n"
     ]
    }
   ],
   "source": [
    "# Vérifiez s'il y a des valeurs manquantes dans les colonnes latitudes et longitudes\n",
    "print(stops[['stop_lat', 'stop_lon']].isnull().sum())\n",
    "\n",
    "# Vérifiez également les valeurs uniques pour vous assurer qu'elles sont valides\n",
    "print(stops[['stop_lat', 'stop_lon']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70e3a68a-6153-4649-b1ce-385e51362718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_pt_lat    0\n",
      "shape_pt_lon    0\n",
      "dtype: int64\n",
      "       shape_pt_lat  shape_pt_lon\n",
      "count   6534.000000   6534.000000\n",
      "mean      49.110260      6.177018\n",
      "std        0.025946      0.046127\n",
      "min       48.998825      6.003117\n",
      "25%       49.097190      6.151972\n",
      "50%       49.110841      6.177025\n",
      "75%       49.126479      6.207790\n",
      "max       49.204139      6.324477\n"
     ]
    }
   ],
   "source": [
    "# Vérifiez s'il y a des valeurs manquantes dans les colonnes latitudes et longitudes de shapes\n",
    "print(shapes[['shape_pt_lat', 'shape_pt_lon']].isnull().sum())\n",
    "\n",
    "# Vérifiez également les statistiques de shapes\n",
    "print(shapes[['shape_pt_lat', 'shape_pt_lon']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be402943-b4a1-4ff9-809e-d8f6bd526c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smoha\\AppData\\Local\\Temp\\ipykernel_11432\\780427563.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  qualite_air_drop_metz['Last Updated'] = pd.to_datetime(qualite_air_drop_metz['Last Updated'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      City            Location Pollutant   Unit  Value  \\\n",
      "419   METZ          Metz-Borny        NO  µg/m³    1.8   \n",
      "418   METZ          Metz-Borny       NO2  µg/m³    7.0   \n",
      "812   METZ          Metz-Borny      PM10  µg/m³   12.7   \n",
      "528   METZ          Metz-Borny     PM2.5  µg/m³    0.9   \n",
      "2399  METZ          Metz-Borny       SO2  µg/m³    0.0   \n",
      "319   METZ         Metz-Centre        NO  µg/m³    2.3   \n",
      "691   METZ         Metz-Centre       NO2  µg/m³   13.1   \n",
      "1910  METZ         Metz-Centre        O3  µg/m³   56.6   \n",
      "1684  METZ         Metz-Centre      PM10  µg/m³   11.2   \n",
      "2111  METZ         Metz-Centre     PM2.5  µg/m³    4.7   \n",
      "1792  METZ  Metz- Pont Grilles        CO  µg/m³  218.0   \n",
      "397   METZ  Metz- Pont Grilles        NO  µg/m³   25.8   \n",
      "2096  METZ  Metz- Pont Grilles       NO2  µg/m³   22.4   \n",
      "302   METZ  Metz- Pont Grilles      PM10  µg/m³   10.2   \n",
      "\n",
      "                  Last Updated  qualite_id           Latitude  \\\n",
      "419  2024-03-11 09:00:00+00:00           1   49.1102830002213   \n",
      "418  2024-12-18 15:00:00+00:00           2   49.1102830002213   \n",
      "812  2024-12-17 22:00:00+00:00           3   49.1102830002213   \n",
      "528  2023-04-12 13:00:00+00:00           4   49.1102830002213   \n",
      "2399 2019-08-28 07:00:00+00:00           5   49.1102830002213   \n",
      "319  2024-03-11 09:00:00+00:00           6  49.11944200020038   \n",
      "691  2024-12-18 15:00:00+00:00           7  49.11944200020038   \n",
      "1910 2024-12-18 15:00:00+00:00           8  49.11944200020038   \n",
      "1684 2024-12-18 15:00:00+00:00           9  49.11944200020038   \n",
      "2111 2024-12-18 15:00:00+00:00          10  49.11944200020038   \n",
      "1792 2019-04-11 08:00:00+00:00          11  49.12508000010211   \n",
      "397  2024-03-11 09:00:00+00:00          12  49.12508000010211   \n",
      "2096 2024-12-18 15:00:00+00:00          13  49.12508000010211   \n",
      "302  2024-12-17 22:00:00+00:00          14  49.12508000010211   \n",
      "\n",
      "              Longitude  \n",
      "419   6.223336000400217  \n",
      "418   6.223336000400217  \n",
      "812   6.223336000400217  \n",
      "528   6.223336000400217  \n",
      "2399  6.223336000400217  \n",
      "319   6.180832999656292  \n",
      "691   6.180832999656292  \n",
      "1910  6.180832999656292  \n",
      "1684  6.180832999656292  \n",
      "2111  6.180832999656292  \n",
      "1792  6.181219000343986  \n",
      "397   6.181219000343986  \n",
      "2096  6.181219000343986  \n",
      "302   6.181219000343986  \n"
     ]
    }
   ],
   "source": [
    "calendar = pd.read_csv(\"C:/Users/smoha/DataLake_Groupe5/transport_data/scheduling/calendar/service_calendar.csv\", sep = \";\")\n",
    "trips = pd.read_csv(\"C:/Users/smoha/DataLake_Groupe5/transport_data/scheduling/trips/transit_trips.csv\", sep = \";\")\n",
    "population = pd.read_excel(\"C:/Users/smoha/DataLake_Groupe5/demographics/historical_population_communes_1876_2022.xlsx\", header = 5)\n",
    "stop_time = pd.read_csv(\"C:/Users/smoha/DataLake_Groupe5/transport_data/operations/stop_times/trip_stop_times.csv\", sep = \";\")\n",
    "\n",
    "\n",
    "qualite_air = pd.read_csv(\"C:/Users/smoha/DataLake_Groupe5/environmental_data/Air_quality/air_quality_measurements.csv\", sep = \";\")\n",
    "\n",
    "# ETL sur qualité de l'air du pays\n",
    "\n",
    "qualite_air_drop = qualite_air.drop(columns=['Country Code', 'Country Label', 'Source Name'])\n",
    "\n",
    "qualite_air_drop['Last Updated'] = pd.to_datetime(qualite_air_drop['Last Updated'], utc=True)\n",
    "qualite_air_drop_ = qualite_air_drop.dropna(subset=['City'])\n",
    "\n",
    "#ETL sur la qualité de l'air seuelemnt à Metz\n",
    "qualite_air_drop_metz = qualite_air_drop[qualite_air_drop['City'].str.lower() == 'metz']\n",
    "import pandas as pd\n",
    "\n",
    "qualite_air_drop_metz['Last Updated'] = pd.to_datetime(qualite_air_drop_metz['Last Updated'])\n",
    "\n",
    "#Grouper par 'Coordinates' et 'Pollutant' et garder la dernière mise à jour\n",
    "Qualite_Air = qualite_air_drop_metz.loc[\n",
    "    qualite_air_drop_metz.groupby(['Coordinates', 'Pollutant'])['Last Updated'].idxmax()\n",
    "]\n",
    "\n",
    "#Création d'un id\n",
    "Qualite_Air[\"qualite_id\"] = range(1, len(Qualite_Air) + 1)\n",
    "\n",
    "#Séparer la colonne coordonnée en deux colonnes : lattitude et longitude\n",
    "Qualite_Air[['Latitude', 'Longitude']] = Qualite_Air['Coordinates'].str.extract(r'\\s*([\\d\\.\\-]+),\\s*([\\d\\.\\-]+)')\n",
    "Qualite_Air = Qualite_Air.drop(columns=['Coordinates'])\n",
    "\n",
    "print(Qualite_Air)\n",
    "\n",
    "\n",
    "# ETL Trips \n",
    "\n",
    "#Supprimer les colonnes 'trip_headsign', 'direction_id', 'block_id'\n",
    "colonnes_a_supprimer = ['trip_headsign', 'direction_id', 'block_id']\n",
    "trips_nettoye = trips.drop(columns=colonnes_a_supprimer)\n",
    "\n",
    "#Supprimer les lignes dupliquées\n",
    "trips_nettoye = trips_nettoye.drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Construction table de fait\n",
    "\n",
    "# Joindre stop_times et trips pour obtenir trip_id et service_id\n",
    "fact_table = pd.merge(stop_time, trips, on='trip_id', how='inner')\n",
    "\n",
    "# Ajouter des informations supplémentaires sur les arrêts depuis stops.csv\n",
    "fact_table = pd.merge(fact_table, stops, on='stop_id', how='inner')\n",
    "\n",
    "# Garder uniquement les colonnes nécessaires : stop_id, trip_id, service_id, arrival_time, departure_time\n",
    "fact_table = fact_table[['stop_id', 'trip_id', 'service_id']]\n",
    "\n",
    "Lien = stops[['stop_id',  'stop_lon', 'stop_lat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a82bf6c-2dae-40a0-9f29-1fbffe095548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      City            Location Pollutant   Unit  Value  \\\n",
      "419   METZ          Metz-Borny        NO  µg/m³    1.8   \n",
      "418   METZ          Metz-Borny       NO2  µg/m³    7.0   \n",
      "812   METZ          Metz-Borny      PM10  µg/m³   12.7   \n",
      "528   METZ          Metz-Borny     PM2.5  µg/m³    0.9   \n",
      "2399  METZ          Metz-Borny       SO2  µg/m³    0.0   \n",
      "319   METZ         Metz-Centre        NO  µg/m³    2.3   \n",
      "691   METZ         Metz-Centre       NO2  µg/m³   13.1   \n",
      "1910  METZ         Metz-Centre        O3  µg/m³   56.6   \n",
      "1684  METZ         Metz-Centre      PM10  µg/m³   11.2   \n",
      "2111  METZ         Metz-Centre     PM2.5  µg/m³    4.7   \n",
      "1792  METZ  Metz- Pont Grilles        CO  µg/m³  218.0   \n",
      "397   METZ  Metz- Pont Grilles        NO  µg/m³   25.8   \n",
      "2096  METZ  Metz- Pont Grilles       NO2  µg/m³   22.4   \n",
      "302   METZ  Metz- Pont Grilles      PM10  µg/m³   10.2   \n",
      "\n",
      "                  Last Updated  qualite_id   Latitude  Longitude  stop_id  \n",
      "419  2024-03-11 09:00:00+00:00           1  49.110283   6.223336     6305  \n",
      "418  2024-12-18 15:00:00+00:00           2  49.110283   6.223336     6305  \n",
      "812  2024-12-17 22:00:00+00:00           3  49.110283   6.223336     6305  \n",
      "528  2023-04-12 13:00:00+00:00           4  49.110283   6.223336     6305  \n",
      "2399 2019-08-28 07:00:00+00:00           5  49.110283   6.223336     6305  \n",
      "319  2024-03-11 09:00:00+00:00           6  49.119442   6.180833      556  \n",
      "691  2024-12-18 15:00:00+00:00           7  49.119442   6.180833      556  \n",
      "1910 2024-12-18 15:00:00+00:00           8  49.119442   6.180833      556  \n",
      "1684 2024-12-18 15:00:00+00:00           9  49.119442   6.180833      556  \n",
      "2111 2024-12-18 15:00:00+00:00          10  49.119442   6.180833      556  \n",
      "1792 2019-04-11 08:00:00+00:00          11  49.125080   6.181219       26  \n",
      "397  2024-03-11 09:00:00+00:00          12  49.125080   6.181219       26  \n",
      "2096 2024-12-18 15:00:00+00:00          13  49.125080   6.181219       26  \n",
      "302  2024-12-17 22:00:00+00:00          14  49.125080   6.181219       26  \n",
      "      stop_id  stop_lon   stop_lat   distance\n",
      "0          57  6.138669  49.099805   4.182131\n",
      "1          46  6.138371  49.099927   4.189146\n",
      "2         450  6.146239  49.085890   5.047172\n",
      "3         852  6.145297  49.086159   5.056485\n",
      "4         323  6.034971  49.191534  12.950041\n",
      "...       ...       ...        ...        ...\n",
      "1041      864  6.113065  49.077468   7.255867\n",
      "1042      878  6.228467  49.071125   6.915753\n",
      "1043      877  6.228486  49.070906   6.937579\n",
      "1044      875  6.159053  49.159749   4.178631\n",
      "1045      884  6.158544  49.158829   4.099209\n",
      "\n",
      "[1046 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "link = Lien\n",
    "airqual = Qualite_Air\n",
    "\n",
    "# Convertir les champs en float (et forcer la conversion si possible)\n",
    "link['stop_lon'] = pd.to_numeric(link['stop_lon'], errors='coerce')\n",
    "link['stop_lat'] = pd.to_numeric(link['stop_lat'], errors='coerce')\n",
    "airqual['Longitude'] = pd.to_numeric(airqual['Longitude'], errors='coerce')\n",
    "airqual['Latitude'] = pd.to_numeric(airqual['Latitude'], errors='coerce')\n",
    "\n",
    "# Fonction pour calculer la distance Haversine\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    R = 6371  # Rayon de la Terre en kilomètres\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "# Seuil de proximité en kilomètres\n",
    "threshold = 0.5  # Ajustez selon vos besoins\n",
    "\n",
    "# Ajouter une colonne pour l'ID de l'arrêt de bus le plus proche\n",
    "airqual['stop_id'] = None\n",
    "\n",
    "# Calcul des distances et mise à jour du stop_id\n",
    "for index, air_quality in airqual.iterrows():\n",
    "    air_lon, air_lat = air_quality['Longitude'], air_quality['Latitude']\n",
    "    \n",
    "    # Calculer la distance entre le point de qualité de l'air et tous les arrêts de bus\n",
    "    link['distance'] = link.apply(\n",
    "        lambda row: haversine(air_lon, air_lat, row['stop_lon'], row['stop_lat']), axis=1\n",
    "    )\n",
    "    \n",
    "    # Trouver l'arrêt de bus le plus proche\n",
    "    nearest_bus = link[link['distance'] <= threshold].sort_values(by='distance').head(1)\n",
    "    \n",
    "    if not nearest_bus.empty:\n",
    "        # Extraire l'ID de l'arrêt de bus le plus proche\n",
    "        nearest_stop_id = nearest_bus['stop_id'].values[0]\n",
    "        \n",
    "        # Mettre à jour la colonne `stop_id` dans le DataFrame `airqual`\n",
    "        airqual.at[index, 'stop_id'] = nearest_stop_id\n",
    "\n",
    "airqual['stop_id'] = airqual['stop_id'].astype(int)\n",
    "\n",
    "# Résultat\n",
    "print(airqual)\n",
    "print(link)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cc8e495a-7578-4e3a-bd71-85f4fac2780b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables disponibles : ['dim_calendar', 'air_quality', 'dim_stops', 'fact_table', 'dim_trips', 'link']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connexion PostgreSQL \n",
    "engine = create_engine('postgresql+psycopg2://postgres:28sUp11ViN25cI01@localhost:5432/Transports_Metz') \n",
    "try:\n",
    "    # Test de connexion\n",
    "    connection = engine.connect()\n",
    "    \n",
    "    # Inspecter les tables existantes\n",
    "    inspector = inspect(engine)\n",
    "    tables = inspector.get_table_names()\n",
    "    print(f\"Tables disponibles : {tables}\")\n",
    "    \n",
    "    connection.close()  # Fermez la connexion proprement\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de l'interrogation : {e}\")\n",
    "\n",
    "# Charger les données dans PostgreSQL \n",
    "fact_table.to_sql('fact_table', engine, if_exists='replace', \n",
    "index=False) \n",
    "\n",
    "#Charger les données dans PostgreSQL \n",
    "link.to_sql('link', engine, if_exists='replace', \n",
    "index=False)\n",
    "\n",
    "# Charger les données dans PostgreSQL \n",
    "trips_nettoye.to_sql('dim_trips', engine, if_exists='replace', \n",
    "index=False)\n",
    "\n",
    "#Charger les données dans PostgreSQL \n",
    "airqual.to_sql('air_quality', engine, if_exists='replace', \n",
    "index=False)\n",
    "\n",
    "#Charger les données dans PostgreSQL \n",
    "stops.to_sql('dim_stops', engine, if_exists='replace', \n",
    "index=False)\n",
    "\n",
    "#Charger les données dans PostgreSQL \n",
    "calendar.to_sql('dim_calendar', engine, if_exists='replace', \n",
    "index=False)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61db87-160f-45e7-8f59-fe8df54d5d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carte sur les arrêts de bus à Metz\n",
    "import folium\n",
    "\n",
    "map_center = [stops['stop_lat'].mean(), stops['stop_lon'].mean()]\n",
    "m = folium.Map(location=map_center, zoom_start=12)\n",
    "\n",
    "# Ajouter des marqueurs pour chaque arrêt de transport\n",
    "for _, row in stops.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['stop_lat'], row['stop_lon']],\n",
    "        popup=row['stop_name'],  # Nom de l'arrêt affiché lors du clic sur le marqueur\n",
    "        icon=folium.Icon(color='blue')\n",
    "    ).add_to(m)\n",
    "\n",
    "# Sauvegarder la carte dans un fichier HTML et l'ouvrir dans votre navigateur\n",
    "m.save(\"C:/Users/smoha/DataLake_Groupe5/stops_map.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07c38c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carte sur la pollution en France \n",
    "latest_per_city = qualite_air_drop_.loc[qualite_air_drop.groupby('City')['Last Updated'].idxmax()]\n",
    "\n",
    "latest_per_city_no2 = latest_per_city[latest_per_city['Pollutant'] == 'NO2']\n",
    "\n",
    "m = folium.Map(location=[46.603354, 1.888334], zoom_start=6)\n",
    "\n",
    "# Définir une échelle de couleurs basée sur la valeur de NO2\n",
    "norm = colors.Normalize(vmin=latest_per_city_no2['Value'].min(), vmax=latest_per_city_no2['Value'].max())\n",
    "colormap = cm.get_cmap('RdYlGn_r')  # Rouge pour haute pollution, vert pour basse pollution\n",
    "\n",
    "# Ajouter des marqueurs pour chaque ligne du DataFrame filtré\n",
    "for _, row in latest_per_city_no2.iterrows():\n",
    "    # Extraire les informations\n",
    "    city = row['City']\n",
    "    lat, lon = map(float, row['Coordinates'].strip('()').split(','))\n",
    "    value = row['Value']\n",
    "    last_updated = row['Last Updated']\n",
    "    \n",
    "    # Calculer la couleur en fonction de la valeur de NO2\n",
    "    color = colors.rgb2hex(colormap(norm(value)))\n",
    "\n",
    "    # Créer un popup d'informations\n",
    "    popup_text = f\"\"\"\n",
    "    <b>City:</b> {city}<br>\n",
    "    <b>NO2 Value:</b> {value} µg/m³<br>\n",
    "    <b>Last Updated:</b> {last_updated}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Style différent pour Metz\n",
    "    if city.lower() == \"metz\":\n",
    "        folium.Marker(\n",
    "            location=[lat, lon],\n",
    "            icon=folium.Icon(color='orange', icon='star'),\n",
    "            popup=folium.Popup(popup_text, max_width=300)\n",
    "        ).add_to(m)\n",
    "    else:\n",
    "        # Ajouter un cercle coloré pour les autres villes\n",
    "        folium.CircleMarker(\n",
    "            location=[lat, lon],\n",
    "            radius=10,  # Taille du marqueur\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.7,\n",
    "            popup=folium.Popup(popup_text, max_width=300)\n",
    "        ).add_to(m)\n",
    "\n",
    "# Ajouter une légende pour l'échelle de couleur\n",
    "from branca.colormap import linear\n",
    "linear_colormap = linear.RdYlGn_11.scale(latest_per_city_no2['Value'].min(), latest_per_city_no2['Value'].max())\n",
    "linear_colormap.caption = 'NO2 Pollution Level (µg/m³)'\n",
    "linear_colormap.add_to(m)\n",
    "\n",
    "# Sauvegarder la carte dans un fichier HTML\n",
    "m.save('C:/Cours/M1/Entrepot de données/Projet/air_quality_map_no2_with_color_scale.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ce815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carte sur la pollution à Metz\n",
    "\n",
    "latest_per_city = qualite_air_drop_.loc[qualite_air_drop.groupby('City')['Last Updated'].idxmax()]\n",
    "\n",
    "latest_per_city_no2 = latest_per_city[latest_per_city['Pollutant'] == 'NO2']\n",
    "\n",
    "m = folium.Map(location=[46.603354, 1.888334], zoom_start=6)\n",
    "\n",
    "# Définir une échelle de couleurs basée sur la valeur de NO2\n",
    "norm = colors.Normalize(vmin=latest_per_city_no2['Value'].min(), vmax=latest_per_city_no2['Value'].max())\n",
    "colormap = cm.get_cmap('RdYlGn_r')  # Rouge pour haute pollution, vert pour basse pollution\n",
    "\n",
    "# Ajouter des marqueurs pour chaque ligne du DataFrame filtré\n",
    "for _, row in latest_per_city_no2.iterrows():\n",
    "    # Extraire les informations\n",
    "    city = row['City']\n",
    "    lat, lon = map(float, row['Coordinates'].strip('()').split(','))\n",
    "    value = row['Value']\n",
    "    last_updated = row['Last Updated']\n",
    "    \n",
    "    # Calculer la couleur en fonction de la valeur de NO2\n",
    "    color = colors.rgb2hex(colormap(norm(value)))\n",
    "\n",
    "    # Créer un popup d'informations\n",
    "    popup_text = f\"\"\"\n",
    "    <b>City:</b> {city}<br>\n",
    "    <b>NO2 Value:</b> {value} µg/m³<br>\n",
    "    <b>Last Updated:</b> {last_updated}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Style différent pour Metz\n",
    "    if city.lower() == \"metz\":\n",
    "        folium.Marker(\n",
    "            location=[lat, lon],\n",
    "            icon=folium.Icon(color='orange', icon='star'),\n",
    "            popup=folium.Popup(popup_text, max_width=300)\n",
    "        ).add_to(m)\n",
    "    else:\n",
    "        # Ajouter un cercle coloré pour les autres villes\n",
    "        folium.CircleMarker(\n",
    "            location=[lat, lon],\n",
    "            radius=10,  # Taille du marqueur\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.7,\n",
    "            popup=folium.Popup(popup_text, max_width=300)\n",
    "        ).add_to(m)\n",
    "\n",
    "# Ajouter une légende pour l'échelle de couleur\n",
    "linear_colormap = linear.RdYlGn_11.scale(latest_per_city_no2['Value'].min(), latest_per_city_no2['Value'].max())\n",
    "linear_colormap.caption = 'NO2 Pollution Level (µg/m³)'\n",
    "linear_colormap.add_to(m)\n",
    "\n",
    "# Sauvegarder la carte dans un fichier HTML\n",
    "m.save('C:/Cours/M1/Entrepot de données/Projet/air_quality_map_no2_with_color_scale.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
